---
# ----------------------------------------------------------------------------------------
# -- Docs: https://github.com/cluster-apps-on-docker/spark-standalone-cluster-on-docker --
# ----------------------------------------------------------------------------------------
version: "3.6"
volumes:
  shared-workspace:
    name: "hadoop-distributed-file-system"
    driver: local
services:
  postgres:
    image: postgres:12
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5433:5432"
  scheduler:
    image: spark-airflow:2.0.0-spark-3.0.1
    container_name: airflow-scheduler
    restart: always
    depends_on:
      - postgres
      - webserver
    env_file:
      - ./docker/airflow/environment
    ports:
      - "8793:8793"
    volumes:
      - ./docker/airflow/dags:/opt/airflow/dags
      - ./docker/airflow/airflow-logs:/opt/airflow/logs
    command: scheduler
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3
  webserver:
    image: spark-airflow:2.0.0-spark-3.0.1
    container_name: airflow-webserver
    hostname: webserver
    restart: always
    depends_on:
      - postgres
    env_file:
      - ./docker/airflow/environment
    volumes:
      - ./docker/airflow/dags:/opt/airflow/dags
      - ./docker/airflow/scripts:/opt/airflow/scripts
      - ./docker/airflow/airflow-logs:/opt/airflow/logs
    ports:
      - "8090:8080"
    entrypoint: /opt/airflow/scripts/airflow-entrypoint.sh
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 32
  jupyterlab:
    image: jupyterlab:3.0.5-spark-3.0.1
    container_name: jupyterlab
    ports:
      - 8888:8888
      - 4040:4040
    volumes:
      - shared-workspace:/opt/workspace
  spark-master:
    image: spark-master:3.0.1
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    volumes:
      - shared-workspace:/opt/workspace
  spark-worker-1:
    image: spark-worker:3.0.1
    container_name: spark-worker-1
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=512m
    ports:
      - 8081:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
  spark-worker-2:
    image: spark-worker:3.0.1
    container_name: spark-worker-2
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=512m
    ports:
      - 8082:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
